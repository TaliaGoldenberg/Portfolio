[
  {
    "objectID": "cv/index.html",
    "href": "cv/index.html",
    "title": "Curriculum vitae",
    "section": "",
    "text": "Download current CV"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "This project analyzed data about Bachelors, Masters, and Doctorate degrees. Specifically looking at number of degrees and type of degrees by race & ethnicity and field of study. This project helped me grow skills such as cleaning, merging, and analyzing large data sets in R to answer questions about diversity in higher education. This project also grew my skills in dealing with data sets with many NA values, which can make data visualization and drawing sound conclusions about data more difficult.\nBelow you’ll find code looking at linear regression for Bachelors, Masters, and Doctorate degrees.\n#----Linear Regression-----\n\n#BACHELOR'S DEGREES\ndsLR_BS=ds %&gt;%\n  filter(degree==\"Bachelor's\") %&gt;%\n  group_by(Year) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents))\n  \ndsLR_BS %&gt;%\n  ggplot(aes(x=Year, y=totalstudents)) +\n  geom_point()+\n  geom_smooth(method = \"lm\")+\n  scale_x_continuous(breaks = 2011:2020)+\n  scale_y_continuous(labels=scales::comma_format())+\n  labs (title=\"Bachleor's Degrees Obtained Overtime\", x=\"Year\", y=\"Number of Degrees\") +\n  theme_minimal ()\n\nlm(totalstudents~Year,data = dsLR_BS)\n#slope 19908 this is telling me that for every year over this time period, the number of people perusing this degree went up by roughly 20,000\n\n#MASTER'S DEGREES\ndsLR_M=ds %&gt;%\n  filter(degree==\"Master's\") %&gt;%\n  group_by(Year) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents))\n\ndsLR_M %&gt;%\n  ggplot(aes(x=Year, y=totalstudents)) +\n  geom_point()+\n  geom_smooth(method = \"lm\")+\n  scale_x_continuous(breaks = 2011:2020)+\n  scale_y_continuous(labels=scales::comma_format())+\n  labs (title=\"Master's Degrees Obtained Overtime\", x=\"Year\", y=\"Number of Degrees\") +\n  theme_minimal ()\n\nlm(totalstudents~Year,data = dsLR_M)\n\n\n#DOCTORATE DEGREES\ndsLR_D=ds %&gt;%\n  filter(degree==\"Doctorate\") %&gt;%\n  group_by(Year) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents))\n\ndsLR_D %&gt;%\n  ggplot(aes(x=Year, y=totalstudents)) +\n  geom_point()+\n  geom_smooth(method = \"lm\")+\n  scale_x_continuous(breaks = 2011:2020)+\n  scale_y_continuous(labels=scales::comma_format())+\n  labs (title=\"Doctorate Degrees Obtained Overtime\", x=\"Year\", y=\"Number of Degrees\") +\n  theme_minimal ()\n\nlm(totalstudents~Year,data = dsLR_D)\nNext I made new data sets with the NA values removed to highlight the differences.\n#-----How to visualize/understand NA data-----\nhead(ds)\n\ndsNA=ds %&gt;%\n  group_by(degree, `Broad field`, `Race and ethnicity`) %&gt;%\nsummarise(totalstudents=sum(numberOfStudents))\n\ndsNA=dsNA %&gt;%\n  mutate(`Race and ethnicity`=ifelse(is.na(`Race and ethnicity`),\"Unknown\",`Race and ethnicity`))\n\ndsNA_B=ds %&gt;%\n  filter(degree==\"Bachelor's\") %&gt;%\n  group_by(`Broad field`) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents)) %&gt;%\n  arrange(totalstudents) %&gt;%\n  pull(`Broad field`)\n\n#BACHELOR'S DEGREES\ndsNA %&gt;%\n  filter(degree==\"Bachelor's\") %&gt;%\n  mutate(`Broad field`=factor(`Broad field`,levels=dsNA_B)) %&gt;%\n  ggplot(aes(y=`Broad field`, x=totalstudents, fill=`Race and ethnicity`))+\n  geom_col()+\n  scale_x_continuous(labels=scales::comma_format())+\nlabs (title=\"Degrees Awarded 2011-2020\",subtitle = \"Bachelor's\", x=\"Number of Degrees\", y=\"Broad Field of Study\") +\n  theme_minimal ()\n\ndsNA_M=ds %&gt;%\n  filter(degree==\"Master's\") %&gt;%\n  group_by(`Broad field`) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents)) %&gt;%\n  arrange(totalstudents) %&gt;%\n  pull(`Broad field`)\n\n#MASTER'S DEGREES\ndsNA %&gt;%\n  filter(degree==\"Master's\") %&gt;%\n  mutate(`Broad field`=factor(`Broad field`,levels=dsNA_M)) %&gt;%\n  ggplot(aes(y=`Broad field`, x=totalstudents, fill=`Race and ethnicity`))+\n  geom_col()+\n  scale_x_continuous(labels=scales::comma_format())+\n  labs (title=\"Degrees Awarded 2011-2020\",subtitle = \"Master's\", x=\"Number of Degrees\", y=\"Broad Field of Study\") +\n  theme_minimal ()\n\ndsNA_D=ds %&gt;%\n  filter(degree==\"Doctorate\") %&gt;%\n  group_by(`Broad field`) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents)) %&gt;%\n  arrange(totalstudents) %&gt;%\n  pull(`Broad field`)\n\n#DOCTORATE DEGREES\ndsNA %&gt;%\n  filter(degree==\"Doctorate\") %&gt;%\n  mutate(`Broad field`=factor(`Broad field`,levels=dsNA_D)) %&gt;%\n  ggplot(aes(y=`Broad field`, x=totalstudents, fill=`Race and ethnicity`))+\n  geom_col()+\n  scale_x_continuous(labels=scales::comma_format())+\n  labs (title=\"Degrees Awarded 2011-2020\",subtitle = \"Doctorate\", x=\"Number of Degrees\", y=\"Broad Field of Study\") +\n  theme_minimal ()\nMore data visualization.\n#For legibility, facet it vertically instead of horizontally or pick a different visualization\n\nhead(ds)\n\ndsCOL=ds %&gt;%\n  group_by(degree, `Broad field`, `Race and ethnicity`, Year) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents))\n  \n#BACHELOR'S\ndsCOL %&gt;%\n  filter(degree==\"Bachelor's\") %&gt;%\n  ggplot(aes(x=Year, y=totalstudents, fill=`Race and ethnicity`)) +\n  geom_col() +\n  scale_x_continuous(breaks = 2011:2020)+\n  scale_y_continuous(labels=scales::comma_format())+\n  labs (title=\"Total Number of Degrees Awarded by Race and Ethnicity\",subtitle = \"Bachelor's\", x=\"Year\", y=\"Number of Degrees\") +\n  theme_minimal ()\n\n#MASTER'S\ndsCOL %&gt;%\n  filter(degree==\"Master's\") %&gt;%\n  ggplot(aes(x=Year, y=totalstudents, fill=`Race and ethnicity`)) +\n  geom_col() +\n  scale_x_continuous(breaks = 2011:2020)+\n  scale_y_continuous(labels=scales::comma_format())+\n  labs (title=\"Total Number of Degrees Awarded by Race and Ethnicity\",subtitle = \"Master's\", x=\"Year\", y=\"Number of Degrees\") +\n  theme_minimal ()\n\n#DOCTORATE\ndsCOL %&gt;%\n  filter(degree==\"Doctorate\") %&gt;%\n  ggplot(aes(x=Year, y=totalstudents, fill=`Race and ethnicity`)) +\n  geom_col() +\n  scale_x_continuous(breaks = 2011:2020)+\n  scale_y_continuous(labels=scales::comma_format())+\n  labs (title=\"Total Number of Degrees Awarded by Race and Ethnicity\",subtitle = \"Doctorate\", x=\"Year\", y=\"Number of Degrees\") +\n  theme_minimal ()\nLastly, I made an overall data set with all degrees and made more graphs to help answer questions about the data set.\n#-----OTHER---------\ndsOverall=ds %&gt;%\n  group_by(degree, Year) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents)) %&gt;%\n  mutate(degree=factor(degree, levels=c(\"Bachelor's\",\"Master's\",\"Doctorate\")))\n\nlevels(dsOverall$degree)\n\n\ndsOverall=dsCOL %&gt;%\n  group_by(degree, Year) %&gt;%\n  summarise(totalstudents=sum(totalstudents))\n\ndsOverall=dsOverall %&gt;%\n  mutate(degree=factor(degree, levels=\"Bachelor's\",\"Master's\",\"Doctorate\")) \n\n\ndsOverall%&gt;%\n  ggplot(aes(x=Year, y=totalstudents, color=degree)) +\n  geom_point()+\n  geom_smooth(method=\"lm\")+\n  scale_x_continuous(breaks = 2011:2020)+\n  scale_y_continuous(labels=scales::comma_format())+\n  scale_color_discrete(name=\"Degree\")+\n  labs (title=\"Total Number of Degrees Awarded Between 2011-2020\", x=\"Year\", y=\"Number of Degrees\") +\n  theme_minimal ()\n\nunique(dsOverall$degree)"
  },
  {
    "objectID": "projects/index.html#how-diverse-is-higher-education",
    "href": "projects/index.html#how-diverse-is-higher-education",
    "title": "Projects",
    "section": "",
    "text": "This project analyzed data about Bachelors, Masters, and Doctorate degrees. Specifically looking at number of degrees and type of degrees by race & ethnicity and field of study. This project helped me grow skills such as cleaning, merging, and analyzing large data sets in R to answer questions about diversity in higher education. This project also grew my skills in dealing with data sets with many NA values, which can make data visualization and drawing sound conclusions about data more difficult.\nBelow you’ll find code looking at linear regression for Bachelors, Masters, and Doctorate degrees.\n#----Linear Regression-----\n\n#BACHELOR'S DEGREES\ndsLR_BS=ds %&gt;%\n  filter(degree==\"Bachelor's\") %&gt;%\n  group_by(Year) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents))\n  \ndsLR_BS %&gt;%\n  ggplot(aes(x=Year, y=totalstudents)) +\n  geom_point()+\n  geom_smooth(method = \"lm\")+\n  scale_x_continuous(breaks = 2011:2020)+\n  scale_y_continuous(labels=scales::comma_format())+\n  labs (title=\"Bachleor's Degrees Obtained Overtime\", x=\"Year\", y=\"Number of Degrees\") +\n  theme_minimal ()\n\nlm(totalstudents~Year,data = dsLR_BS)\n#slope 19908 this is telling me that for every year over this time period, the number of people perusing this degree went up by roughly 20,000\n\n#MASTER'S DEGREES\ndsLR_M=ds %&gt;%\n  filter(degree==\"Master's\") %&gt;%\n  group_by(Year) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents))\n\ndsLR_M %&gt;%\n  ggplot(aes(x=Year, y=totalstudents)) +\n  geom_point()+\n  geom_smooth(method = \"lm\")+\n  scale_x_continuous(breaks = 2011:2020)+\n  scale_y_continuous(labels=scales::comma_format())+\n  labs (title=\"Master's Degrees Obtained Overtime\", x=\"Year\", y=\"Number of Degrees\") +\n  theme_minimal ()\n\nlm(totalstudents~Year,data = dsLR_M)\n\n\n#DOCTORATE DEGREES\ndsLR_D=ds %&gt;%\n  filter(degree==\"Doctorate\") %&gt;%\n  group_by(Year) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents))\n\ndsLR_D %&gt;%\n  ggplot(aes(x=Year, y=totalstudents)) +\n  geom_point()+\n  geom_smooth(method = \"lm\")+\n  scale_x_continuous(breaks = 2011:2020)+\n  scale_y_continuous(labels=scales::comma_format())+\n  labs (title=\"Doctorate Degrees Obtained Overtime\", x=\"Year\", y=\"Number of Degrees\") +\n  theme_minimal ()\n\nlm(totalstudents~Year,data = dsLR_D)\nNext I made new data sets with the NA values removed to highlight the differences.\n#-----How to visualize/understand NA data-----\nhead(ds)\n\ndsNA=ds %&gt;%\n  group_by(degree, `Broad field`, `Race and ethnicity`) %&gt;%\nsummarise(totalstudents=sum(numberOfStudents))\n\ndsNA=dsNA %&gt;%\n  mutate(`Race and ethnicity`=ifelse(is.na(`Race and ethnicity`),\"Unknown\",`Race and ethnicity`))\n\ndsNA_B=ds %&gt;%\n  filter(degree==\"Bachelor's\") %&gt;%\n  group_by(`Broad field`) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents)) %&gt;%\n  arrange(totalstudents) %&gt;%\n  pull(`Broad field`)\n\n#BACHELOR'S DEGREES\ndsNA %&gt;%\n  filter(degree==\"Bachelor's\") %&gt;%\n  mutate(`Broad field`=factor(`Broad field`,levels=dsNA_B)) %&gt;%\n  ggplot(aes(y=`Broad field`, x=totalstudents, fill=`Race and ethnicity`))+\n  geom_col()+\n  scale_x_continuous(labels=scales::comma_format())+\nlabs (title=\"Degrees Awarded 2011-2020\",subtitle = \"Bachelor's\", x=\"Number of Degrees\", y=\"Broad Field of Study\") +\n  theme_minimal ()\n\ndsNA_M=ds %&gt;%\n  filter(degree==\"Master's\") %&gt;%\n  group_by(`Broad field`) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents)) %&gt;%\n  arrange(totalstudents) %&gt;%\n  pull(`Broad field`)\n\n#MASTER'S DEGREES\ndsNA %&gt;%\n  filter(degree==\"Master's\") %&gt;%\n  mutate(`Broad field`=factor(`Broad field`,levels=dsNA_M)) %&gt;%\n  ggplot(aes(y=`Broad field`, x=totalstudents, fill=`Race and ethnicity`))+\n  geom_col()+\n  scale_x_continuous(labels=scales::comma_format())+\n  labs (title=\"Degrees Awarded 2011-2020\",subtitle = \"Master's\", x=\"Number of Degrees\", y=\"Broad Field of Study\") +\n  theme_minimal ()\n\ndsNA_D=ds %&gt;%\n  filter(degree==\"Doctorate\") %&gt;%\n  group_by(`Broad field`) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents)) %&gt;%\n  arrange(totalstudents) %&gt;%\n  pull(`Broad field`)\n\n#DOCTORATE DEGREES\ndsNA %&gt;%\n  filter(degree==\"Doctorate\") %&gt;%\n  mutate(`Broad field`=factor(`Broad field`,levels=dsNA_D)) %&gt;%\n  ggplot(aes(y=`Broad field`, x=totalstudents, fill=`Race and ethnicity`))+\n  geom_col()+\n  scale_x_continuous(labels=scales::comma_format())+\n  labs (title=\"Degrees Awarded 2011-2020\",subtitle = \"Doctorate\", x=\"Number of Degrees\", y=\"Broad Field of Study\") +\n  theme_minimal ()\nMore data visualization.\n#For legibility, facet it vertically instead of horizontally or pick a different visualization\n\nhead(ds)\n\ndsCOL=ds %&gt;%\n  group_by(degree, `Broad field`, `Race and ethnicity`, Year) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents))\n  \n#BACHELOR'S\ndsCOL %&gt;%\n  filter(degree==\"Bachelor's\") %&gt;%\n  ggplot(aes(x=Year, y=totalstudents, fill=`Race and ethnicity`)) +\n  geom_col() +\n  scale_x_continuous(breaks = 2011:2020)+\n  scale_y_continuous(labels=scales::comma_format())+\n  labs (title=\"Total Number of Degrees Awarded by Race and Ethnicity\",subtitle = \"Bachelor's\", x=\"Year\", y=\"Number of Degrees\") +\n  theme_minimal ()\n\n#MASTER'S\ndsCOL %&gt;%\n  filter(degree==\"Master's\") %&gt;%\n  ggplot(aes(x=Year, y=totalstudents, fill=`Race and ethnicity`)) +\n  geom_col() +\n  scale_x_continuous(breaks = 2011:2020)+\n  scale_y_continuous(labels=scales::comma_format())+\n  labs (title=\"Total Number of Degrees Awarded by Race and Ethnicity\",subtitle = \"Master's\", x=\"Year\", y=\"Number of Degrees\") +\n  theme_minimal ()\n\n#DOCTORATE\ndsCOL %&gt;%\n  filter(degree==\"Doctorate\") %&gt;%\n  ggplot(aes(x=Year, y=totalstudents, fill=`Race and ethnicity`)) +\n  geom_col() +\n  scale_x_continuous(breaks = 2011:2020)+\n  scale_y_continuous(labels=scales::comma_format())+\n  labs (title=\"Total Number of Degrees Awarded by Race and Ethnicity\",subtitle = \"Doctorate\", x=\"Year\", y=\"Number of Degrees\") +\n  theme_minimal ()\nLastly, I made an overall data set with all degrees and made more graphs to help answer questions about the data set.\n#-----OTHER---------\ndsOverall=ds %&gt;%\n  group_by(degree, Year) %&gt;%\n  summarise(totalstudents=sum(numberOfStudents)) %&gt;%\n  mutate(degree=factor(degree, levels=c(\"Bachelor's\",\"Master's\",\"Doctorate\")))\n\nlevels(dsOverall$degree)\n\n\ndsOverall=dsCOL %&gt;%\n  group_by(degree, Year) %&gt;%\n  summarise(totalstudents=sum(totalstudents))\n\ndsOverall=dsOverall %&gt;%\n  mutate(degree=factor(degree, levels=\"Bachelor's\",\"Master's\",\"Doctorate\")) \n\n\ndsOverall%&gt;%\n  ggplot(aes(x=Year, y=totalstudents, color=degree)) +\n  geom_point()+\n  geom_smooth(method=\"lm\")+\n  scale_x_continuous(breaks = 2011:2020)+\n  scale_y_continuous(labels=scales::comma_format())+\n  scale_color_discrete(name=\"Degree\")+\n  labs (title=\"Total Number of Degrees Awarded Between 2011-2020\", x=\"Year\", y=\"Number of Degrees\") +\n  theme_minimal ()\n\nunique(dsOverall$degree)"
  },
  {
    "objectID": "projects/index.html#how-does-minecraft-version-affect-success-rate",
    "href": "projects/index.html#how-does-minecraft-version-affect-success-rate",
    "title": "Projects",
    "section": "How Does Minecraft Version Affect Success Rate",
    "text": "How Does Minecraft Version Affect Success Rate\nThis experiment investigates whether or not a person’s Minecraft experience level influences their ability to perform and accomplish a task, particularly finding diamond ores. To answer this question, I designed an experiment where 50 Willamette student, ages 18-24, were randomly assigned one of two Minecraft versions and were categorized by self-assessed player levels: Noob, Intermediate, and Expert. Each participant had 30 minutes in a randomly generated world to collect as many diamonds as they could with the game settings standardized across three devices to minimize confounding factors. The response variables of total diamonds collected, number of deaths, experience points, and time until the first diamond was collected and analyzed through statistical functions in R and data visualization. Findings from this experimental analysis indicate a clear correlation between a player’s experience level and their success rate in finding diamonds, with expert players dominating each category and showcasing more advanced skills in gathering diamonds.\nBelow I created two data sets, one with and one without, NA values to visualize Time to First Diamond and Player Experience.\nds_no_NA %&gt;%\nggplot(aes(x=`Time to First Diamond (min)`))+\n  geom_histogram(fill=\"forestgreen\", color=\"black\", binwidth = 1)+\n  labs (title=\"Number of Players by Time to First Diamond (min)\", \n        x=\"Time to First Diamond (min)\",\n        y=\"Number of Players\") +\n  scale_x_continuous(breaks = 8:30)+\n  theme_bw ()\n\ndsALL %&gt;%\n  ggplot(aes(x=`Player Experience`))+\n  geom_bar(fill=\"forestgreen\", color=\"black\")+\n  labs (title=\"Player Self-Assessed Level\", \n        x=\"Player Experience\",\n        y=\"Number of Players\") +\n  theme_bw ()\n\ndsALL %&gt;%\n  ggplot(aes(x=`Player Experience`, y=`Number of Deaths`))+\n  geom_boxplot(fill=\"forestgreen\", color=\"black\")+\n  facet_grid(.~`Player Experience`)+\n  labs (title=\"Player Experience by XP\", \n        x=\"XP\",\n        y=\"Player Experience\") +\n  theme_bw ()\nThis code shows a Tukey test. This compares each player’s skill level versus the number of deaths to see if there is any noticeable correlation. This shows that some of the values cross over the 0 line meaning that there must not be statistical significance between any of the different possible combinations. It also shows that all of our P-values are far above the 0.05 threshold meaning that we fail to reject the null hypothesis. Meaning there is not enough evidence to suggest a statistical difference.\ntukey2=aov(`Number.of.Deaths`~`Player.Experience`,data=ds)\ntukeyModel2=TukeyHSD(tukey2,conf.level=0.95)\ntukeyModel2\nplot(tukeyModel2)\nThe following code is for a linear regression. Overall this linear regression satisfies all the components of a LINE test as well as has independent observations as discussed earlier. However, there is some cause for concern as some of the data does not look perfect, thus future research should keep this in mind.\nmod5=lm(`Diamonds.Found`~`XP`,data=ds)\nsummary(mod5)\npar(mfrow=c(2,2))\nplot(mod5)"
  },
  {
    "objectID": "experience/index.html",
    "href": "experience/index.html",
    "title": "Experience",
    "section": "",
    "text": "I’ve had the privilege of working with Odyssey World International on their Community Asset Map project. On this mapping initiative, I review “listening sessions” to extract key insights and aggregated data on healthcare providers of color in Clark County WA to create a Community Asset Map, ensuring marginalized communities can access culturally competent care."
  },
  {
    "objectID": "experience/index.html#odyssey-world-international",
    "href": "experience/index.html#odyssey-world-international",
    "title": "Experience",
    "section": "",
    "text": "I’ve had the privilege of working with Odyssey World International on their Community Asset Map project. On this mapping initiative, I review “listening sessions” to extract key insights and aggregated data on healthcare providers of color in Clark County WA to create a Community Asset Map, ensuring marginalized communities can access culturally competent care."
  },
  {
    "objectID": "experience/index.html#coursework",
    "href": "experience/index.html#coursework",
    "title": "Experience",
    "section": "Coursework",
    "text": "Coursework\nIn my Survey Design and Sampling Methodology course I gained valuable skills that I’ve been able to apply to other Data Science positions. Over the semester I developed experience cleaning and visualizing PUMs and PUMA data, carefully designing surveys and sampling strategies to minimize bias, completed CITI/IRB training to expand piratical knowledge for handling sensitive date, and more! Through my coursework at Willamette, I have expanded my technical skill set in addition to the valuable relationship building skills necessary to work as a community to affect change."
  },
  {
    "objectID": "experience/index.html#lgbtq-center-oc",
    "href": "experience/index.html#lgbtq-center-oc",
    "title": "Experience",
    "section": "LGBTQ Center OC",
    "text": "LGBTQ Center OC\nMy work at the LGBTQ Center in Orange County CA involved analyzing survey statistics to measure program success, designing data-driven presentations, and researching policy topics related to mental health and advocacy. Other projects I was assigned through this position involved restorative justice work, an educational social media campaign on the War on Drugs, and workshops on alcohol, tobacco & other drugs (ATOD)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my GitHub Portfolio!",
    "section": "",
    "text": "Github\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Email\n  \n\n\n\n\nWelcome to my GitHub Portfolio!\nHello! My name is Talia (they/them). I am a Data Science and Sociology major at Willamette University. I’m passionate about taking the technical skills associated with Data Science and combining it with the collective action, advocacy, and community organizing skills gained through Sociology.\nOutside of academics, I’m an Audio Visual Technician, Vice President of Willamette University’s Headband A Cappella, Data Science Tutor, and Data Science Teaching Assistant.\nPlease feel free to contact me if you have any questions or would like to discuss potential projects."
  },
  {
    "objectID": "Goldenberg_HW7.html",
    "href": "Goldenberg_HW7.html",
    "title": "DATA429 HW7",
    "section": "",
    "text": "In the previous example from Class 7B the SRS, not all departments were represented. The following data are from a stratified sample using academic division. The total number of faculty in Biological Sciences is 102, Physical Science is 310, Social Sciences is 217, and Humanities is 178 in the population.\nWhat is the proportion with no refereed publications?\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npubStr&lt;-read.csv(\"https://raw.githubusercontent.com/kitadasmalley/Teaching/refs/heads/main/DATA429_599/CODE/pubStrat.csv\", \n                 header=TRUE)\n\nhead(pubStr)\n\n  Publications Biological Physical Social Humanities\n1            0          1       10      9          8\n2            1          2        2      0          2\n3            2          0        0      1          0\n4            3          1        1      0          1\n5            4          0        2      2          0\n6            5          2        1      0          0\n\n\n\n### BIOLOGICAL\nn1&lt;-sum(pubStr$Biological)\nphat1&lt;-pubStr$Biological[1]/n1\n\n### PHYSICAL\nn2&lt;-sum(pubStr$Physical)\nphat2&lt;-pubStr$Physical[1]/n2\n\n### SOCIAL\nn3&lt;-sum(pubStr$Social)\nphat3 = pubStr$Social[1]/n3\n\n### HUMANITIES\nn4&lt;-sum(pubStr$Humanities)\nphat4 = pubStr$Humanities[1]/n4\n\n\n### COMBINE\nN=807\nNh=c(102,310,217,178)\nnh = c(n1,n2,n3,n4)\n\nphats = c(phat1, phat2, phat3, phat4)\n\n## P HAT STRAT\np_hat_strat = sum((Nh/N) * phats)\np_hat_strat\n\n[1] 0.5668087\n\n## STD ERR\nvar_phat_strat = sum((1-(nh/Nh))*((Nh/N)^2)*((phats*(1-phats))/(nh-1)))\n                \nstdErr_phat_strat = sqrt(var_phat_strat)\nstdErr_phat_strat\n\n[1] 0.06583449\n\n## CONF INT -&gt; 90%\nconf = p_hat_strat+c(-1,1)*qnorm(.95)*sqrt(var_phat_strat)\nconf\n\n[1] 0.4585206 0.6750968\n\n\n\n\nThe proportion of faculty with no refereed publications is 0.5666 or 56.6%. The standard error is 0.0658. The confidence interval is 0.4583, 0.6749"
  },
  {
    "objectID": "Goldenberg_HW7.html#problem-1",
    "href": "Goldenberg_HW7.html#problem-1",
    "title": "DATA429 HW7",
    "section": "",
    "text": "In the previous example from Class 7B the SRS, not all departments were represented. The following data are from a stratified sample using academic division. The total number of faculty in Biological Sciences is 102, Physical Science is 310, Social Sciences is 217, and Humanities is 178 in the population.\nWhat is the proportion with no refereed publications?\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npubStr&lt;-read.csv(\"https://raw.githubusercontent.com/kitadasmalley/Teaching/refs/heads/main/DATA429_599/CODE/pubStrat.csv\", \n                 header=TRUE)\n\nhead(pubStr)\n\n  Publications Biological Physical Social Humanities\n1            0          1       10      9          8\n2            1          2        2      0          2\n3            2          0        0      1          0\n4            3          1        1      0          1\n5            4          0        2      2          0\n6            5          2        1      0          0\n\n\n\n### BIOLOGICAL\nn1&lt;-sum(pubStr$Biological)\nphat1&lt;-pubStr$Biological[1]/n1\n\n### PHYSICAL\nn2&lt;-sum(pubStr$Physical)\nphat2&lt;-pubStr$Physical[1]/n2\n\n### SOCIAL\nn3&lt;-sum(pubStr$Social)\nphat3 = pubStr$Social[1]/n3\n\n### HUMANITIES\nn4&lt;-sum(pubStr$Humanities)\nphat4 = pubStr$Humanities[1]/n4\n\n\n### COMBINE\nN=807\nNh=c(102,310,217,178)\nnh = c(n1,n2,n3,n4)\n\nphats = c(phat1, phat2, phat3, phat4)\n\n## P HAT STRAT\np_hat_strat = sum((Nh/N) * phats)\np_hat_strat\n\n[1] 0.5668087\n\n## STD ERR\nvar_phat_strat = sum((1-(nh/Nh))*((Nh/N)^2)*((phats*(1-phats))/(nh-1)))\n                \nstdErr_phat_strat = sqrt(var_phat_strat)\nstdErr_phat_strat\n\n[1] 0.06583449\n\n## CONF INT -&gt; 90%\nconf = p_hat_strat+c(-1,1)*qnorm(.95)*sqrt(var_phat_strat)\nconf\n\n[1] 0.4585206 0.6750968\n\n\n\n\nThe proportion of faculty with no refereed publications is 0.5666 or 56.6%. The standard error is 0.0658. The confidence interval is 0.4583, 0.6749"
  },
  {
    "objectID": "Goldenberg_HW7.html#problem-2",
    "href": "Goldenberg_HW7.html#problem-2",
    "title": "DATA429 HW7",
    "section": "PROBLEM 2",
    "text": "PROBLEM 2\n\n#### PUBLIC HEALTH\nph&lt;-read.csv(\"https://raw.githubusercontent.com/kitadasmalley/Teaching/refs/heads/main/DATA429_599/CODE/healthjournals.csv\", \n             header=TRUE)\n\nstr(ph)\n\n'data.frame':   198 obs. of  7 variables:\n $ Journal   : chr  \"AJPH\" \"AJPH\" \"AJPH\" \"AJPH\" ...\n $ NumAuthors: int  4 9 6 5 7 4 3 4 2 4 ...\n $ RandomSel : chr  \"No\" \"No\" \"No\" \"No\" ...\n $ RandomAssn: chr  \"No\" \"No\" \"No\" \"No\" ...\n $ ConfInt   : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ HypTest   : chr  \"No\" \"Yes\" \"Yes\" \"Yes\" ...\n $ Asterisks : chr  \"No\" \"No\" \"No\" \"No\" ...\n\n\n\nPart A - Sampling Weight\n\nNh = c(280,103,164)\n\nnh = c(100,38,60)\nN = sum(Nh)\n\nsamp_weights = Nh/nh\nsamp_weights\n\n[1] 2.800000 2.710526 2.733333\n\n\nThe sampling weight for each stratum is:\nAmerican Journal of Public Health: 2.8\nAmerican Journal of Preventive Medicine: 2.711\nPreventive Medicine: 2.733\nThe sample design used proportional allocation.\n\n\nPart B - Percentage of articles that used things\n\nOnly Confidence Intervals\n\n#TOTAL ESTIMATE\nph01 = ph %&gt;% mutate(confint01 = (ConfInt == \"Yes\")) %&gt;% group_by (Journal) %&gt;%\n  summarize(p_hat01=mean(confint01, na.rm=TRUE),\n            nh=n())\nph01\n\n# A tibble: 3 × 3\n  Journal p_hat01    nh\n  &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt;\n1 AJPH      0.76    100\n2 AJPM      0.474    38\n3 PM        0.8      60\n\nconfinest = sum((Nh/N)*ph01$p_hat01)\n#0.71808\n\n#CI for hypothesis test \n#VAR\nphat_var_strat = sum(((Nh/N)^2)*(1-(nh/Nh))*((ph01$p_hat01*(1-ph01$p_hat01))/(nh-1)))\n\n#SE\nSE = sqrt(phat_var_strat)\nSE\n\n[1] 0.0248133\n\n#CI\nconff_int =confinest+c(-1,1)*qnorm(.975)*sqrt(phat_var_strat)\nconff_int\n\n[1] 0.6694463 0.7667126\n\n\nThe percentage of articles that used only CIs is 71.81%, with a 95% confidence interval from 66.9% to 76.7%.\n\n\nOnly Hypothesis testing\n\nph02 = ph %&gt;% mutate(hypt01 = (HypTest == \"Yes\")) %&gt;% group_by (Journal) %&gt;%\n  summarize(p_h02=mean(hypt01, na.rm=TRUE),\n            nh=n())\nph02\n\n# A tibble: 3 × 3\n  Journal p_h02    nh\n  &lt;chr&gt;   &lt;dbl&gt; &lt;int&gt;\n1 AJPH    0.85    100\n2 AJPM    0.816    38\n3 PM      0.867    60\n\nhypt_est = sum((Nh/N)*ph02$p_h02)\n#0.84856\n\n#CI for hypothesis test \n#VAR\nphat_var_strat = sum(((Nh/N)^2)*(1-(nh/Nh))*((ph02$p_h02*(1-ph02$p_h02))/(nh-1)))\n\n#SE\nse = sqrt(phat_var_strat)\n\n#CI\nhyp_int =hypt_est+c(-1,1)*qnorm(.975)*sqrt(phat_var_strat)\n\nThe percentage of articles that used hypothesis tests only is 84.86%, with a 95% confidence interval from 80.84% to 88.87% of articles.\n\n\nBoth confidence intervals and hypothesis testing\n\nph03 = ph %&gt;% mutate(cihyp = (HypTest == \"Yes\" & ConfInt == \"Yes\")) %&gt;% group_by (Journal) %&gt;%\n  summarize(p_h03=mean(cihyp, na.rm=TRUE),\n            nh=n())\nph03\n\n# A tibble: 3 × 3\n  Journal p_h03    nh\n  &lt;chr&gt;   &lt;dbl&gt; &lt;int&gt;\n1 AJPH    0.68    100\n2 AJPM    0.368    38\n3 PM      0.717    60\n\nboth_est = sum((Nh/N)*ph03$p_h03)\n#0.6323\n\n#CI for hypothesis test \n#VAR\nphat_var_strat = sum(((Nh/N)^2)*(1-(nh/Nh))*((ph03$p_h03*(1-ph03$p_h03))/(nh-1)))\n\n#SE\nse = sqrt(phat_var_strat)\n\n#CI\nboth_int =both_est+c(-1,1)*qnorm(.975)*sqrt(phat_var_strat)\nboth_int\n\n[1] 0.5802035 0.6844425\n\n\nThe percentage of articles that used both Confidence Intervals and hypothesis testing is 63.23%, with a 95% confidence interval from 58.02% to 68.44%.\n\n\n\nNeither Confidence Intervals nor Hypothesis testing\n\nph04 = ph %&gt;% mutate(non = (HypTest == \"No\" & ConfInt == \"No\")) %&gt;% group_by (Journal) %&gt;%\n  summarize(p_h04=mean(non, na.rm=TRUE),\n            nh=n())\nph04\n\n# A tibble: 3 × 3\n  Journal  p_h04    nh\n  &lt;chr&gt;    &lt;dbl&gt; &lt;int&gt;\n1 AJPH    0.07     100\n2 AJPM    0.0789    38\n3 PM      0.05      60\n\nnon_est = sum((Nh/N)*ph04$p_h04)\n#0.0657\n\n#CI for hypothesis test \n#VAR\nphat_var_strat = sum(((Nh/N)^2)*(1-(nh/Nh))*((ph04$p_h04*(1-ph04$p_h04))/(nh-1)))\n\n#SE\nse = sqrt(phat_var_strat)\n\n#CI\nnon_int =non_est+c(-1,1)*qnorm(.975)*sqrt(phat_var_strat)\nnon_int\n\n[1] 0.03792664 0.09345025\n\n\nThe percentage of articles that used neither Confidence Intervals nor hypothesis testing is 6.57%, with a 95% confidence interval from 3.79% to 9.35%.\n\n\n\nPART C\nGive a point estimate and 95% CI for the mean number of authors per article\n\n#Y BARS\nph06 = ph %&gt;% group_by (Journal) %&gt;%\n  summarize(p_h06=mean(NumAuthors, na.rm=TRUE),vars=var(NumAuthors, na.rm=TRUE),\n            nh=n())\nph06\n\n# A tibble: 3 × 4\n  Journal p_h06  vars    nh\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 AJPH     4.88  5.40   100\n2 AJPM     5.58  7.17    38\n3 PM       6.3  14.5     60\n\ny_bar_strat = sum((Nh/N) * ph06$p_h06)\ny_bar_strat\n\n[1] 5.437352\n\nn=sum(ph06$nh)\nvar_ybar_strat = sum((Nh/N)^2 * ((1-(nh/Nh))*(ph06$vars/nh)))\n\n#SE\nstdErr_ybar_strat = sqrt(var_ybar_strat)\n\n#CI\ny_bar_strat + c(-1,1)*qt(.975, 198-3)*stdErr_ybar_strat\n\n[1] 5.112817 5.761887\n\n\nThe point estimate is 5.437. The confidence interval is 5.113, 5.762 for both confidence interval and hypothesis tests.\n\n\nPART D\nEstimate the percentage and total number of articles (among the 547 in the population) that use neither random selection nor random assignment, along with 95% CIs.\n\nPercentage\n\nph05 = ph %&gt;% mutate(nont = (RandomSel == \"No\" & RandomAssn == \"No\")) %&gt;% group_by (Journal) %&gt;%\n  summarize(p_h05=mean(nont, na.rm=TRUE),\n            nh=n())\nph05\n\n# A tibble: 3 × 3\n  Journal p_h05    nh\n  &lt;chr&gt;   &lt;dbl&gt; &lt;int&gt;\n1 AJPH    0.67    100\n2 AJPM    0.526    38\n3 PM      0.633    60\n\nnont_est = sum((Nh/N)*ph05$p_h05)\n#0.63195\n\n#CI for hypothesis test \n#VAR\nphat_var_strat = sum(((Nh/N)^2)*(1-(nh/Nh))*((ph05$p_h05*(1-ph05$p_h05))/(nh-1)))\n\n#SE\nse = sqrt(phat_var_strat)\n\n#CI\nnont_int =nont_est+c(-1,1)*qnorm(.975)*sqrt(phat_var_strat)\nnont_int\n\n[1] 0.5782278 0.6856742\n\n\nThe percentage of articles that used neither confidence intervals nor hypothesis testing is 63.195%, with a 95% confidence interval from 57.8% to 68.6%.\n\n\nTotal\n\ntot_est = N*nont_est\n\n#CI\nphat_var_strat = sum(((Nh/N)^2)*(1-(nh/Nh))*((ph05$p_h05*(1-ph05$p_h05))/(nh-1)))\n\n\n#do both proportions and totals use qnorm? why?\ntot_int=tot_est+c(-1,1)*qnorm(.975)*sqrt(N^2*phat_var_strat)\ntot_int\n\n[1] 316.2906 375.0638\n\n\nThe estimated total number of articles that used neither confidence intervals nor hypothesis testing is 345 (result was 345.677), with a 95% confidence interval from 316 to 375.\n\n\n\nPART E\nDo the statistics calculated in this exercise describe all public health research articles? To what population do they apply?\n\nANSWER:\nThe statistics in this exercise do not describe all public health research articles. They apply only to the scope in which the data was collected. While these statistics can provide insights, it’s likely not representative."
  }
]